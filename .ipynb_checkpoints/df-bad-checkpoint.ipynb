{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bad Example\n",
    "\\begin{align*}\n",
    "& x_{n+1}=(I+\\eta \\left[\\begin{matrix}0.1 & 0.5 \\\\ 0 & 0.1 \\end{matrix}\\right]) x_n+\\sqrt{\\eta}\\left[\\begin{matrix}0.7 & -0.6 \\\\ 0 & 0.7 \\end{matrix}\\right]u_n, \\quad x_0=\\left[\\begin{matrix} 1 \\\\ -1 \\end{matrix}\\right]\\\\\n",
    "& y_n=\\left[\\begin{matrix}0 & 1 \\end{matrix}\\right]x_n+\\sigma_0 v_n, \\quad \\sigma_0=0.5\n",
    "\\end{align*}\n",
    "\n",
    "That is to say\n",
    "\\begin{align*}\n",
    "x_{n+1}=F x_n+G u_n\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "& F=I+\\eta F0=I+\\eta \\left[\\begin{matrix}0.1 & 0.5 \\\\ 0 & 0.1 \\end{matrix}\\right] \\\\\n",
    "& G=\\sqrt{\\eta}\\left[\\begin{matrix}0.7 & -0.6 \\\\ 0 & 0.7 \\end{matrix}\\right]\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-5f14e8d15278>:72: RuntimeWarning: overflow encountered in multiply\n",
      "  R[k+1]=F@(R[k]-(R[k]@H.T*np.linalg.inv(H@R[k]@H.T+R0)@H)*R[k])@F.T+G@Q0@G.T            #!!!\n",
      "<ipython-input-1-5f14e8d15278>:72: RuntimeWarning: invalid value encountered in matmul\n",
      "  R[k+1]=F@(R[k]-(R[k]@H.T*np.linalg.inv(H@R[k]@H.T+R0)@H)*R[k])@F.T+G@Q0@G.T            #!!!\n",
      "<ipython-input-1-5f14e8d15278>:71: RuntimeWarning: invalid value encountered in matmul\n",
      "  x_hat[k+1]=F@x_hat[k]+F@R[k]@H.T*np.linalg.inv(H@R[k]@H.T+R0)*(y_raw[k]-H@x_hat[k]) #!!!\n",
      "<ipython-input-1-5f14e8d15278>:73: RuntimeWarning: invalid value encountered in matmul\n",
      "  x_bar=[x_hat[k]+R[k]@H.T*np.linalg.inv(H@R[k]@H.T+R0)*(y_raw[k]-H@x_hat[k]) for k in range(N+1)]\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------\n",
    "# library loading\n",
    "#--------------------------------------\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "#set suppress to not use scientific counting\n",
    "#np.set_printoptions(suppress=True) \n",
    "\n",
    "#----------------------------------------\n",
    "# Initialization Math Model\n",
    "#----------------------------------------\n",
    "cpu_start=time.perf_counter()\n",
    "\n",
    "dimX=2; dimY=1  \n",
    "sigma0_train=0.5; eta=0.005\n",
    "N=500; n0=50; N_sample= 1000\n",
    "\n",
    "#Deterministic Matrix\n",
    "F0=np.array([[0.1,0.5],[0,0.1]],dtype='float64')\n",
    "F=np.eye(dimX)+eta*F0\n",
    "G=np.sqrt(eta)*np.array([[0.7,-0.6],[0,0.7]],dtype='float64')\n",
    "H=np.array([[0,1]],dtype='float64')\n",
    "x0=np.array([[1],[-1]],dtype='float64')\n",
    "\n",
    "#Covariance Matrix for random variable\n",
    "Q0=np.eye(dimX) #random variable u_n\n",
    "R0=sigma0_train*sigma0_train*np.eye(dimY) #random variable v_n\n",
    "\n",
    "# generate u_n, v_n\n",
    "# 1-d Gaussian: np.random.default_rng().normal(mean, std, size)\n",
    "# n-d Gaussian: np.random.default_rng().multivariate_normal(mean,cov,size)\n",
    "# note to reshape multivariate normal random variable to column vector.\n",
    "rng=np.random.default_rng()\n",
    "u=[rng.multivariate_normal(np.zeros(dimX),np.eye(dimX),1).reshape(dimX,1) for i in range(N)] #!!!\n",
    "v=[rng.multivariate_normal(np.zeros(dimY),np.eye(dimY),1).reshape(dimY,1) for i in range(N+1)] #!!!\n",
    "u=np.array(u)\n",
    "v=np.array(v)\n",
    "\n",
    "#--------------------------------------\n",
    "# Monte Carlo Simulation for once\n",
    "#--------------------------------------\n",
    "def mc_simulation(F,G,H,u,v):\n",
    "    x_raw=np.zeros((N+1,dimX,1),dtype='float64'); x_raw[0]=x0                                     \n",
    "    y_raw=np.zeros((N+1,dimY,1),dtype='float64'); y_raw[0]=H@x0+sigma0_train*v[0] #!!!\n",
    "    \n",
    "    for k in range(N):\n",
    "        x_raw[k+1]=F@x_raw[k]+G@u[k]  #!!!\n",
    "        y_raw[k+1]=H@x_raw[k+1]+sigma0_train*v[k+1] #!!!\n",
    "    \n",
    "    return x_raw, y_raw\n",
    "\n",
    "#----------------------------------\n",
    "# Kalman Filtering Algorithm\n",
    "#----------------------------------\n",
    "def kalman_filtering(F,G,H,Q0,R0,x0,y_raw):\n",
    "    #caution: need to specific x is dimX x 1 to be column vector\n",
    "    x_hat=np.zeros((N+1,dimX,1),dtype='float64'); x_hat[0]=x0\n",
    "    R=np.zeros((N+1,dimX,dimX),dtype='float64'); R[0]=np.zeros((dimX,dimX))  #!!!!!\n",
    "    \n",
    "    if dimY==1:\n",
    "        #y_raw has to be column array or vector.\n",
    "        for k in range(N):\n",
    "            # Q0=np.eye(1) and @ change to *.\n",
    "            x_hat[k+1]=F@x_hat[k]+F@R[k]@H.T*np.linalg.inv(H@R[k]@H.T+R0)*(y_raw[k]-H@x_hat[k]) #!!!\n",
    "            R[k+1]=F@(R[k]-(R[k]@H.T*np.linalg.inv(H@R[k]@H.T+R0)@H)*R[k])@F.T+G@Q0@G.T            #!!!\n",
    "        x_bar=[x_hat[k]+R[k]@H.T*np.linalg.inv(H@R[k]@H.T+R0)*(y_raw[k]-H@x_hat[k]) for k in range(N+1)]\n",
    "    else:\n",
    "        for k in range(N):\n",
    "            x_hat[k+1]=F@x_hat[k]+F@R[k]@H.T@np.linalg.inv(H@R[k]@H.T+R0)@(y_raw[k]-H@x_hat[k]) #!!!\n",
    "            R[k+1]=F@(R[k]-R[k]@H.T@np.linalg.inv(H@R[k]@H.T+R0)@H@R[k])@F.T+G@Q0@G.T           #!!!\n",
    "        x_bar=[x_hat[k]+R[k]@H.T@np.linalg.inv(H@R[k]@H.T+R0)@(y_raw[k]-H@x_hat[k]) for k in range(N+1)]\n",
    "        \n",
    "    #make list to np.array\n",
    "    x_bar=np.array(x_bar) \n",
    "    \n",
    "    return x_hat, x_bar\n",
    "\n",
    "#-----------------------------\n",
    "# Generating tons of samples\n",
    "#-----------------------------\n",
    "\n",
    "def sample_generator():\n",
    "    \n",
    "    datas=np.zeros(((N-n0+2)*N_sample,n0,dimY),dtype='float64') #for each sample path, we have N-n0+2 data\n",
    "    labels=np.zeros(((N-n0+2)*N_sample,dimX),dtype='float64')\n",
    "    \n",
    "    x_bars=np.zeros(((N-n0+2)*N_sample,dimX),dtype='float64') #store Kalman filtering estimation value.\n",
    "    x_hats=np.zeros(((N-n0+2)*N_sample,dimX),dtype='float64')\n",
    "    \n",
    "    x_raws=np.zeros((N_sample, N+1, dimX, 1),dtype='float64')\n",
    "    y_raws=np.zeros((N_sample, N+1, dimY, 1),dtype='float64')\n",
    "    \n",
    "    for i in range(N_sample):\n",
    "        data=np.zeros((N-n0+2,n0,dimY),dtype='float64') #store data for each sample\n",
    "        label=np.zeros((N-n0+2,dimX),dtype='float64')\n",
    "        # call mc_simulation function to generate sample\n",
    "        x_raw,y_raw=mc_simulation(F,G,H,u,v)\n",
    "        x_raws[i]=x_raw; y_raws[i]=y_raw\n",
    "        \n",
    "        # call kalman_filtering function to compute estimation\n",
    "        # make sure here y_raw to be column vector\n",
    "        x_hat, x_bar=kalman_filtering(F,G,H,Q0,R0,x0,y_raw)\n",
    "        \n",
    "        # convert x_raw...into row vector\n",
    "        x_raw=x_raw.reshape(N+1,dimX) \n",
    "        y_raw=y_raw.reshape(N+1,dimY)\n",
    "        x_hat=x_hat.reshape(N+1,dimX)\n",
    "        x_bar=x_bar.reshape(N+1,dimX)\n",
    "        # make data and label for each sample\n",
    "        for k in range(N-n0+2):\n",
    "            data[k]=y_raw[k:k+n0]\n",
    "            label[k]=x_raw[k+n0-1]\n",
    "            \n",
    "        # put data and label into datas and labels with i representing sample number\n",
    "        datas[i*(N-n0+2):(i+1)*(N-n0+2)]=data\n",
    "        labels[i*(N-n0+2):(i+1)*(N-n0+2)]=label\n",
    "        x_hats[i*(N-n0+2):(i+1)*(N-n0+2)]=x_hat[n0-1:]\n",
    "        x_bars[i*(N-n0+2):(i+1)*(N-n0+2)]=x_bar[n0-1:]\n",
    "    \n",
    "    return datas,labels,x_hats,x_bars,x_raws,y_raws\n",
    "\n",
    "#-----------------------------\n",
    "# Data Preparation\n",
    "#-----------------------------\n",
    "# call sample_generator function to generate sample\n",
    "datas, labels, x_hats,x_bars,x_raws, y_raws=sample_generator()\n",
    "datas=datas.reshape(((N-n0+2)*N_sample,dimY*n0))\n",
    "# convert numpy array into pandas dataframe\n",
    "datas=pd.DataFrame(datas)\n",
    "labels=pd.DataFrame(labels)\n",
    "x_hats=pd.DataFrame(x_hats)\n",
    "x_bars=pd.DataFrame(x_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22600/22600 [==============================] - 9s 386us/step - loss: 0.0835 - mean_squared_error: 0.0835\n",
      "Epoch 2/10\n",
      "22600/22600 [==============================] - 9s 388us/step - loss: 0.0482 - mean_squared_error: 0.0482\n",
      "Epoch 3/10\n",
      "22600/22600 [==============================] - 9s 385us/step - loss: 0.0395 - mean_squared_error: 0.0395\n",
      "Epoch 4/10\n",
      "22600/22600 [==============================] - 9s 384us/step - loss: 0.0362 - mean_squared_error: 0.0362\n",
      "Epoch 5/10\n",
      "22600/22600 [==============================] - 9s 385us/step - loss: 0.0348 - mean_squared_error: 0.0348\n",
      "Epoch 6/10\n",
      "22600/22600 [==============================] - 9s 382us/step - loss: 0.0340 - mean_squared_error: 0.0340\n",
      "Epoch 7/10\n",
      "22600/22600 [==============================] - 9s 384us/step - loss: 0.0334 - mean_squared_error: 0.0334\n",
      "Epoch 8/10\n",
      "22600/22600 [==============================] - 9s 389us/step - loss: 0.0329 - mean_squared_error: 0.0329\n",
      "Epoch 9/10\n",
      "22600/22600 [==============================] - 9s 391us/step - loss: 0.0325 - mean_squared_error: 0.0325\n",
      "Epoch 10/10\n",
      "22600/22600 [==============================] - 9s 384us/step - loss: 0.0321 - mean_squared_error: 0.0321\n",
      "2825/2825 [==============================] - 1s 344us/step - loss: 0.0318 - mean_squared_error: 0.0318\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8b3a3e2985ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0mkf_mse_err\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_bars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mcpu_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[0;32m    254\u001b[0m         y_true, y_pred, multioutput)\n\u001b[0;32m    255\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m     84\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    646\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     95\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     96\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     98\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed=3\n",
    "np.random.seed(seed)\n",
    "training_data, test_data, training_label, test_label=train_test_split(datas,labels, test_size=0.2, random_state=seed)\n",
    "\n",
    "# input data normalization\n",
    "data_mean=training_data.mean(axis=0)\n",
    "data_std=training_data.std(axis=0)\n",
    "\n",
    "training_data=(training_data-data_mean)/data_std\n",
    "test_data=(test_data-data_mean)/data_std\n",
    "\n",
    "# output data normalization\n",
    "#label_mean=training_label.mean(axis=0)\n",
    "#label_std=training_label.std(axis=0)\n",
    "\n",
    "#training_label=(training_label-label_mean)/label_std\n",
    "#test_label=(test_label-label_mean)/label_std\n",
    "\n",
    "\n",
    "#-------------------------------\n",
    "# Model building\n",
    "#-------------------------------\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "def build_model():\n",
    "    model=models.Sequential()\n",
    "    model.add(layers.Dense(5,activation='relu',input_shape=(dimY*n0,)))\n",
    "    model.add(layers.Dense(5,activation='relu'))\n",
    "    model.add(layers.Dense(5,activation='relu'))\n",
    "    model.add(layers.Dense(5,activation='relu'))\n",
    "    model.add(layers.Dense(5,activation='relu'))\n",
    "    model.add(layers.Dense(dimX))\n",
    "              \n",
    "    model.compile(optimizer=optimizers.SGD(lr=0.001), \n",
    "                  loss='mean_squared_error', \n",
    "                  metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "model=build_model()\n",
    "mymodel=model.fit(training_data,training_label, epochs=10, batch_size=16)\n",
    "\n",
    "#-------------------------------\n",
    "# Evaluation Performance\n",
    "#-------------------------------\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "test_mse_score, test_mae_score=model.evaluate(test_data,test_label)\n",
    "\n",
    "index=test_label.index.tolist()\n",
    "kf_mse_err=mean_squared_error(x_bars.iloc[index],labels.iloc[index])\n",
    "\n",
    "cpu_end=time.perf_counter()\n",
    "\n",
    "print(\"The mse of deep filtering is {:.3%}\".format(test_mse_score))\n",
    "print(\"The mse of Kalman Filtering is {:.3%}\".format(kf_mse_err))\n",
    "print(\"The CPU consuming time is {:.5}\".format(cpu_end-cpu_start))\n",
    "\n",
    "\n",
    "history_dict=mymodel.history\n",
    "loss_value=history_dict['loss']\n",
    "#val_loss_value=history_dict['val_loss']\n",
    "epochs=range(1,10+1)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epochs, loss_value, 'bo',label='Training Loss')\n",
    "#plt.plot(epochs, val_loss_value,'b',label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# plot on new data\n",
    "#----------------------------------------\n",
    "# new number of time step horizon.\n",
    "#N_new=500\n",
    "x_new,y_new=mc_simulation(F,G,H,u,v)\n",
    "x_hat_new,x_bar_new=kalman_filtering(F,G,H,Q0,R0,x0,y_new)\n",
    "y_new=y_new.reshape(N+1,dimY)\n",
    "data_new=np.zeros((N-n0+2,n0,dimY))\n",
    "for k in range(N-n0+2):\n",
    "    data_new[k]=y_new[k:k+n0]\n",
    "data_new=data_new.reshape(N-n0+2,n0*dimY)\n",
    "data_new=pd.DataFrame(data_new)\n",
    "# input normalization\n",
    "data_new=(data_new-data_mean)/data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep filtering prediction value.\n",
    "df_pred=model.predict(data_new)\n",
    "# convert prediction value to original scale.\n",
    "#for i in range(N_new-n0+2):\n",
    "#    df_pred[i,:]=df_pred[i,:]*label_mean+label_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For estimation before state index n0-1, we use x0 to replace it.\n",
    "df_new=[x0 for k in range(n0-1)]\n",
    "df_new=np.array(df_new)\n",
    "df_new=df_new.reshape(n0-1,dimX)\n",
    "df_new=np.vstack((df_new,df_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis=np.linspace(0,5,N+1)\n",
    "fig,ax=plt.subplots(2,1,figsize=[8,12],sharey=True)\n",
    "ax[0].plot(axis, x_new[:,0],'c',axis,x_bar_new[:,0],'b',axis,df_new[:,0],'r',linewidth=0.5)\n",
    "ax[0].minorticks_on()\n",
    "ax[0].set_xlim((0,5))\n",
    "ax[0].set_ylim((-4,4))\n",
    "ax[1].plot(axis, x_new[:,1],'c',axis, x_bar_new[:,1],'b',axis,df_new[:,1],'r',linewidth=0.6)\n",
    "ax[1].set_xlim((0,5))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
