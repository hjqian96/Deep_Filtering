{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constant Velocity Model in 3D space\n",
    "\n",
    "\\begin{align*}\n",
    "x(k+1)=Fx(k)+u(k)\\\\\n",
    "x=[x,\\dot{x},y,\\dot{y},z,\\dot{z}]'\n",
    "\\end{align*}\n",
    "where the transition matrix $F$ is \n",
    "\\begin{align*}\n",
    "F=\\left[\\begin{matrix}\n",
    "F_1 & 0 & 0 \\\\\n",
    "0 & F_1 & 0 \\\\\n",
    "0 & 0 & F_1\n",
    "\\end{matrix}\\right],\\quad \n",
    "F_1=\\left[\n",
    "\\begin{matrix}\n",
    "1 & T\\\\\n",
    "0 & 1\n",
    "\\end{matrix}\\right]\n",
    "\\end{align*}\n",
    "\n",
    "The noise process $u(k)$ is assumed zero-mean white with covariance\n",
    "\\begin{align*}\n",
    "Q=\\left[\n",
    "\\begin{matrix} \n",
    "u_1 & 0 & 0 \\\\\n",
    "0 & u_1 & 0\\\\\n",
    "0 & 0 & u_1\n",
    "\\end{matrix}\\right],\\quad \n",
    "u_1=\\left[\\begin{matrix}\n",
    "T^4/4 & T^3/2\\\\\n",
    "T^3/2 & T^2\n",
    "\\end{matrix}\n",
    "\\right]q1\n",
    "\\end{align*}\n",
    "\n",
    "The general measurement update is \n",
    "\\begin{align*}\n",
    "z_k=h(x_k)+\\sigma_0v_k\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "h=\\left[\n",
    "\\begin{matrix}\n",
    "r \\\\\n",
    "\\theta \\\\\n",
    "\\varphi\\\\\n",
    "\\end{matrix}\n",
    "\\right] =\\left[\\begin{matrix}\n",
    "\\sqrt{x^2+y^2+z^2} \\\\\n",
    "arctan(y/x)\\\\\n",
    "arctan(z/\\sqrt{x^2+y^2}) \\\\\n",
    "\\end{matrix}\\right],\\quad\n",
    "cov(v_k)=diag(\\sigma_{r}^2,\\sigma_{\\theta}^2,\\sigma_{\\varphi}^2)\n",
    "\\end{align*}\n",
    "\n",
    "#### Parameters Setting\n",
    "\n",
    "$x_0=[900,50,950,40,850,60]'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# library loading\n",
    "#--------------------------------------\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "#set suppress to not use scientific counting\n",
    "np.set_printoptions(suppress=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# Initialization Math Model\n",
    "#----------------------------------------\n",
    "cpu_start=time.perf_counter()\n",
    "\n",
    "# q1: variance of the process noise modeling the acceleration\n",
    "T=0.1; q1=1\n",
    "# qr, qtheta, qphi: std of measure noise.\n",
    "qr=2; qtheta=0.7; qphi=0.2;\n",
    "\n",
    "dimX=6; dimY=3\n",
    "N=1000; n0=50; N_sample= 1000\n",
    "sigma0_train=1\n",
    "\n",
    "#Deterministic Matrix\n",
    "F0=np.array([[1,T,0,0,0,0],\n",
    "            [0,1,0,0,0,0],\n",
    "            [0,0,1,T,0,0],\n",
    "            [0,0,0,1,0,0],\n",
    "            [0,0,0,0,1,T],\n",
    "            [0,0,0,0,0,1]])\n",
    "\n",
    "x0=np.array([[9],\n",
    "             [0.5],\n",
    "             [9.5],\n",
    "             [0.4],\n",
    "             [8.5],\n",
    "             [0.6]])\n",
    "\n",
    "#Covariance Matrix for random variable\n",
    "#random variable u_n\n",
    "Q0=np.array([[np.power(T,4)*q1/4,np.power(T,3)*q1/2,0,0,0,0],\n",
    "             [np.power(T,3)*q1/2,np.power(T,2)*q1,0,0,0,0],\n",
    "             [0,0,np.power(T,4)*q1/4,np.power(T,3)*q1/2,0,0],\n",
    "             [0,0,np.power(T,3)*q1/2,np.power(T,2)*q1,0,0],\n",
    "             [0,0,0,0,np.power(T,4)*q1/4,np.power(T,3)*q1/2],\n",
    "             [0,0,0,0,np.power(T,3)*q1/2,np.power(T,2)*q1]])\n",
    "\n",
    "#random variable v_n\n",
    "R0=np.diag([np.square(qr),np.square(qtheta),np.square(qphi)])\n",
    "\n",
    "# generate u_n, v_n\n",
    "# 1-d Gaussian: np.random.default_rng().normal(mean, std, size)\n",
    "# n-d Gaussian: np.random.default_rng().multivariate_normal(mean,cov,size)\n",
    "# note to reshape multivariate normal random variable to column vector.\n",
    "\n",
    "rng=np.random.default_rng()\n",
    "u=[rng.multivariate_normal(np.zeros(dimX),Q0,1).reshape(dimX,1) for i in range(N)] #!!!\n",
    "v=[rng.multivariate_normal(np.zeros(dimY),R0,1).reshape(dimY,1) for i in range(N+1)] #!!!\n",
    "u=np.array(u)\n",
    "v=np.array(v)\n",
    "\n",
    "#-----------------------------\n",
    "# Function Definition\n",
    "#-----------------------------\n",
    "def f(x):\n",
    "    return F0@x\n",
    "def g(x):\n",
    "    return np.eye(len(x))\n",
    "def h(x):\n",
    "    \"\"\"\n",
    "    input x is a 6-dim col vector, \n",
    "    return a dimY-dim col vector.\"\"\"\n",
    "    res=np.zeros((dimY,1))\n",
    "    res[0]=np.sqrt(np.square(x[0])+np.square(x[2])+np.square(x[4]))\n",
    "    res[1]=np.arctan(x[2]/x[0])\n",
    "    res[2]=np.arctan(x[4]/np.sqrt(np.square(x[0])+np.square(x[2])))\n",
    "    return res\n",
    "def F(x):\n",
    "    \"\"\"Derivative of f \"\"\"\n",
    "    return F0\n",
    "def G(x):\n",
    "    \"\"\"Derivative of g \"\"\"\n",
    "    return np.eye(dimX)\n",
    "def H(x):\n",
    "    \"\"\"\n",
    "    Derivative of h\n",
    "    input a 6-dim col vector, return dimYx6 matrix.\"\"\"\n",
    "    res=np.zeros((dimY,dimX))\n",
    "    res[0][0]=x[0]/np.sqrt(np.square(x[0])+np.square(x[2])+np.square(x[4]))\n",
    "    res[0][2]=x[2]/np.sqrt(np.square(x[0])+np.square(x[2])+np.square(x[4]))\n",
    "    res[0][4]=x[4]/np.sqrt(np.square(x[0])+np.square(x[2])+np.square(x[4]))\n",
    "    \n",
    "    res[1][0]=-x[2]/(np.square(x[0])+np.square(x[2]))\n",
    "    res[1][2]=x[0]/(np.square(x[0])+np.square(x[2]))\n",
    "    \n",
    "    res[2][0]=-(x[0]*x[4])/(np.sqrt(np.square(x[0])+np.square(x[2]))*np.square(x[0])+np.square(x[2])+np.square(x[4]))\n",
    "    res[2][2]=-(x[2]*x[4])/(np.sqrt(np.square(x[0])+np.square(x[2]))*np.square(x[0])+np.square(x[2])+np.square(x[4]))\n",
    "    res[2][4]=np.sqrt(np.square(x[0])+np.square(x[2]))/(np.square(x[0])+np.square(x[2])+np.square(x[4]))\n",
    "                            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#-------------------------------------\n",
    "# Extended KF Monte Carlo\n",
    "#-------------------------------------\n",
    "def ekf_mc(F0,h,u,v,x0,sigma0_train,N):\n",
    "    x_raw=np.zeros((N+1,dimX,1)); x_raw[0]=x0\n",
    "    y_raw=np.zeros((N+1,dimY,1))\n",
    "    y_raw[0]=h(x_raw[0])+sigma0_train*v[0]\n",
    "\n",
    "    for k in range(N):\n",
    "        x_raw[k+1]=F0@x_raw[k]+u[k]  #!!! here is u[k]\n",
    "        y_raw[k+1]=h(x_raw[k+1])+sigma0_train*v[k+1]  #!!! add sigma0_train\n",
    "        \n",
    "    return x_raw,y_raw\n",
    "\n",
    "#-------------------------------------\n",
    "# Extended Kalman Filter Algorithm\n",
    "#-------------------------------------\n",
    "\n",
    "def extended_kf(f,g,h,F,G,H,Q0,R0,x0,y_raw,N):\n",
    "    \"\"\"\n",
    "    f,g,h,F,G,H are all functions.\n",
    "    Q0: covariance matrix of u_n\n",
    "    R0: covariance matrix of v_n \"\"\"\n",
    "    \n",
    "    x_hat=np.zeros((N+1,dimX,1)); x_hat[0]=x0\n",
    "    R=np.zeros((N+1,dimX,dimX)); R[0]=np.eye(dimX) #!!!!!!\n",
    "    x_bar=np.zeros((N+1,dimX,1)) \n",
    "    x_bar[0]=x_hat[0]+R[0]@H(x_hat[0]).T@np.linalg.inv(H(x_hat[0])@R[0]@H(x_hat[0]).T+R0)@(y_raw[0]-h(x_hat[0]))\n",
    "    \n",
    "    for k in range(N):   \n",
    "        x_hat[k+1]=f(x_bar[k])\n",
    "        inv_pre=np.linalg.inv(H(x_hat[k])@R[k]@H(x_hat[k]).T+R0)\n",
    "        R[k+1]=F(x_bar[k])@(R[k]-R[k]@H(x_hat[k]).T@inv_pre@H(x_hat[k])@R[k])@F(x_bar[k]).T+G(x_bar[k])@Q0@G(x_bar[k]).T\n",
    "        inv_pos=np.linalg.inv(H(x_hat[k+1])@R[k+1]@H(x_hat[k+1]).T+R0)\n",
    "        x_bar[k+1]=x_hat[k+1]+R[k+1]@H(x_hat[k+1]).T@inv_pos@(y_raw[k+1]-h(x_hat[k+1]))\n",
    "        \n",
    "    return x_hat,x_bar\n",
    "\n",
    "#-----------------------------------------------------------------------------------------\n",
    "# Generating tons of samples\n",
    "#-----------------------------------------------------------------------------------------\n",
    "\n",
    "def sample_generator(Q0,R0,sigma0_train):\n",
    "    \n",
    "    datas=np.zeros(((N-n0+2)*N_sample,n0,dimY)) #for each sample path, we have N-n0+2 data\n",
    "    labels=np.zeros(((N-n0+2)*N_sample,dimX))\n",
    "    \n",
    "    x_bars=np.zeros(((N-n0+2)*N_sample,dimX)) #store Kalman filtering estimation value.\n",
    "    x_hats=np.zeros(((N-n0+2)*N_sample,dimX))\n",
    "    \n",
    "    x_raws=np.zeros((N_sample, N+1, dimX, 1))\n",
    "    y_raws=np.zeros((N_sample, N+1, dimY, 1))\n",
    "    \n",
    "    for i in range(N_sample):\n",
    "        data=np.zeros((N-n0+2,n0,dimY)) #store data for each sample\n",
    "        label=np.zeros((N-n0+2,dimX))\n",
    "        # call ekf_mc function to generate sample\n",
    "        x_raw,y_raw=ekf_mc(F0,h,u,v,x0,sigma0_train,N)\n",
    "        x_raws[i]=x_raw; y_raws[i]=y_raw\n",
    "        \n",
    "        # call extended_kf function to compute estimation\n",
    "        # make sure here y_raw to be column vector\n",
    "        x_hat, x_bar=extended_kf(f,g,h,F,G,H,Q0,R0,x0,y_raw,N)\n",
    "        \n",
    "        # convert x_raw... into row vector\n",
    "        x_raw=x_raw.reshape(N+1,dimX) \n",
    "        y_raw=y_raw.reshape(N+1,dimY)\n",
    "        x_hat=x_hat.reshape(N+1,dimX)\n",
    "        x_bar=x_bar.reshape(N+1,dimX)\n",
    "        \n",
    "        # make data and label for each sample\n",
    "        for k in range(N-n0+2):\n",
    "            data[k]=y_raw[k:k+n0]\n",
    "            label[k]=x_raw[k+n0-1]\n",
    "            \n",
    "        # put data and label into datas and labels with i representing sample number\n",
    "        datas[i*(N-n0+2):(i+1)*(N-n0+2)]=data\n",
    "        labels[i*(N-n0+2):(i+1)*(N-n0+2)]=label\n",
    "        x_hats[i*(N-n0+2):(i+1)*(N-n0+2)]=x_hat[n0-1:]\n",
    "        x_bars[i*(N-n0+2):(i+1)*(N-n0+2)]=x_bar[n0-1:]\n",
    "    \n",
    "    return datas,labels,x_hats,x_bars,x_raws,y_raws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call sample_generator function to generate sample\n",
    "#datas, labels, x_hats,x_bars,x_raws, y_raws=sample_generator(Q0,R0,sigma0_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#----------------------------------\n",
    "# Deep Filtering Function\n",
    "#----------------------------------\n",
    "\n",
    "def deep_filtering(datas,labels,x_hats,x_bars,x_raws,y_raws):\n",
    "    \"\"\"datas,labels,x_hats,x_bars,x_raws,y_raws\"\"\"\n",
    "    \n",
    "    # Data Preprocessing Procedure\n",
    "    datas=datas.reshape(((N-n0+2)*N_sample,dimY*n0))\n",
    "    # convert numpy array into pandas dataframe\n",
    "    datas=pd.DataFrame(datas)\n",
    "    labels=pd.DataFrame(labels)\n",
    "    x_hats=pd.DataFrame(x_hats)\n",
    "    x_bars=pd.DataFrame(x_bars)\n",
    "    \n",
    "    #from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    seed=3\n",
    "    np.random.seed(seed)\n",
    "    training_data, test_data, training_label, test_label=train_test_split(datas,labels, test_size=0.2, random_state=seed)\n",
    "\n",
    "    # Input normalization\n",
    "    data_mean=training_data.mean(axis=0)\n",
    "    data_std=training_data.std(axis=0)\n",
    "    training_data=(training_data-data_mean)/data_std\n",
    "    test_data=(test_data-data_mean)/data_std\n",
    "\n",
    "    # Output normalization\n",
    "    label_mean=training_label.mean(axis=0)\n",
    "    label_std=training_label.std(axis=0)\n",
    "    training_label=(training_label-label_mean)/label_std\n",
    "    test_label=(test_label-label_mean)/label_std\n",
    "\n",
    "    #-------------------------------\n",
    "    # Model building\n",
    "    #-------------------------------\n",
    "\n",
    "    from keras import models\n",
    "    from keras import layers\n",
    "    from keras import optimizers\n",
    "\n",
    "    def build_model():\n",
    "        model=models.Sequential()\n",
    "        model.add(layers.Dense(5,activation='relu',input_shape=(dimY*n0,)))\n",
    "        model.add(layers.Dense(5,activation='relu'))\n",
    "        model.add(layers.Dense(5,activation='relu'))\n",
    "        model.add(layers.Dense(5,activation='relu'))\n",
    "        model.add(layers.Dense(5,activation='relu'))\n",
    "        model.add(layers.Dense(dimX))\n",
    "\n",
    "        model.compile(optimizer=optimizers.SGD(lr=0.001), \n",
    "                      loss='mean_squared_error', \n",
    "                      metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "        return model\n",
    "\n",
    "    model=build_model()\n",
    "    mymodel=model.fit(training_data,training_label, epochs=10, batch_size=16)\n",
    "\n",
    "    #-------------------------------\n",
    "    # Evaluation Performance\n",
    "    #-------------------------------\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    test_mse_score, test_mae_score=model.evaluate(test_data,test_label)\n",
    "\n",
    "    index=test_label.index.tolist()\n",
    "\n",
    "    # Need to do same normalization with deep filtering to compare.\n",
    "    x_bars=(x_bars-label_mean)/label_std\n",
    "    kf_mse_err=mean_squared_error(x_bars.iloc[index],test_label)\n",
    "\n",
    "    cpu_end=time.perf_counter()\n",
    "\n",
    "    #print(\"The mse of deep filtering is {:.3%}\".format(test_mse_score))\n",
    "    #print(\"The mse of Kalman Filtering is {:.3%}\".format(kf_mse_err))\n",
    "    #print(\"The CPU consuming time is {:.5}\".format(cpu_end-cpu_start))\n",
    "\n",
    "    #history_dict=mymodel.history\n",
    "\n",
    "    #loss_value=history_dict['loss']\n",
    "    #val_loss_value=history_dict['val_loss']\n",
    "    #epochs=range(1,10+1)\n",
    "    #import matplotlib.pyplot as plt\n",
    "    #plt.plot(epochs, loss_value, 'bo',label='Training Loss')\n",
    "    #plt.plot(epochs, val_loss_value,'b',label='Validation Loss')\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "    \n",
    "    return model, data_mean, data_std, label_mean, label_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------\n",
    "# plot on new data\n",
    "#------------------------\n",
    "def graph_plot(N):\n",
    "    \"\"\"N_new: new number of time step horizon.\"\"\"\n",
    "    x_new, y_new=ekf_mc(F0,h,u,v,x0,sigma0_train,N)\n",
    "    x_hat_new, x_bar_new=extended_kf(f,g,h,F,G,H,Q0,R0,x0,y_new,N)\n",
    "    \n",
    "    y_new=y_new.reshape(N+1,dimY)\n",
    "    data_new=np.zeros((N-n0+2,n0,dimY))\n",
    "    for k in range(N-n0+2):\n",
    "        data_new[k]=y_new[k:k+n0]\n",
    "    # convert data to be consistent with deep learning.\n",
    "    data_new=data_new.reshape(N-n0+2,n0*dimY)\n",
    "    data_new=pd.DataFrame(data_new)\n",
    "    # Before predict, normalize data with training information.\n",
    "    data_new=(data_new-data_mean)/data_std\n",
    "    df_pred=model.predict(data_new)\n",
    "    for i in range(N-n0+2):\n",
    "        # convect df results back to original scale.\n",
    "        df_pred[i,:]=df_pred[i,:]*label_std+label_mean\n",
    "    #---------------------------------\n",
    "    # For estimation before state index n0-1, we use x0 to replace it.\n",
    "    \n",
    "    df_new=[x0 for k in range(n0-1)]\n",
    "    df_new=np.array(df_new)\n",
    "    df_new=df_new.reshape(n0-1,dimX)\n",
    "    df_new=np.vstack((df_new,df_pred))\n",
    "\n",
    "    #----------------------------------\n",
    "    plt.figure(dpi = 600,figsize=[30,50])\n",
    "    axis=np.linspace(0,1,N+1)\n",
    "    fig,ax=plt.subplots(3,2,sharex=True)\n",
    "\n",
    "    ax[0][0].plot(axis, x_new[:,0]/1000,'c',axis,x_bar_new[:,0]/1000,'b',axis,df_new[:,0]/1000,'r',linewidth=0.5)\n",
    "    ax[0][0].set_xlim((0,1))\n",
    "    ax[0][0].minorticks_on()\n",
    "    ax[0][1].plot(axis, x_new[:,1],'c',axis,x_bar_new[:,1],'b',axis,df_new[:,1],'r',linewidth=0.5)\n",
    "    ax[0][1].minorticks_on()\n",
    "    ax[1][0].plot(axis, x_new[:,2]/1000,'c',axis,x_bar_new[:,2]/1000,'b',axis,df_new[:,2]/1000,'r',linewidth=0.5)\n",
    "    ax[1][1].plot(axis, x_new[:,3],'c',axis,x_bar_new[:,1],'b',axis,df_new[:,3],'r',linewidth=0.5)\n",
    "    ax[2][0].plot(axis, x_new[:,4]/1000,'c',axis,x_bar_new[:,4]/1000,'b',axis,df_new[:,4]/1000,'r',linewidth=0.5)\n",
    "    ax[2][1].plot(axis, x_new[:,5],'c',axis,x_bar_new[:,5],'b',axis,df_new[:,5],'r',linewidth=0.5)\n",
    "    fig.subplots_adjust(wspace=0.4, hspace=0.3)\n",
    "    plt.savefig('6dim-plot.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# Data backup or Store\n",
    "#--------------------------------\n",
    "# store Monte Carlo sample data\n",
    "#np.save(file='datas/df-CV2D-m2-x_raws.npy',arr=x_raws)\n",
    "#np.save(file='datas/df-CV2D-m2-y_raws.npy',arr=y_raws)\n",
    "# Store training and test data\n",
    "#store=pd.HDFStore('datas/df-CV2D-m2_datas.h5')\n",
    "#store['datas']=datas\n",
    "#store['labels']=labels\n",
    "#store['x_hats']=x_hats\n",
    "#store['x_bars']=x_bars\n",
    "#store['training_data']=training_data\n",
    "#store['training_label']=training_label\n",
    "#store['data_mean']=data_mean\n",
    "#store['data_std']=data_std\n",
    "#store['test_data']=test_data\n",
    "#store['test_label']=test_label\n",
    "#store['label_mean']=label_mean\n",
    "#store['label_std']=label_std\n",
    "# store DNN model\n",
    "#model.save('datas/df-CV2D-m2-model.h5',overwrite=True)\n",
    "# store path data\n",
    "#np.save(file='datas/df-CV2D-m2-x_new',arr=x_new)\n",
    "#np.save(file='datas/df-CV2D-m2-y_new',arr=y_new)\n",
    "#np.save(file='datas/df-CV2D-m2-x_bar_new',arr=x_bar_new)\n",
    "#np.save(file='datas/df-CV2D-m2-df_new',arr=df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Dependence Analysis\n",
    "\n",
    "\\begin{align*}\n",
    "NM:\\begin{cases}\n",
    "x_{k+1}=Fx_k+u_k\\\\\n",
    "z_k=h(x_k)+\\sigma_0^{NM}v_k\n",
    "\\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "AM:\\begin{cases}\n",
    "x_{k+1}=Fx_k+u_k\\\\\n",
    "z_k=h(x_k)+\\sigma_0^{AM}v_k\n",
    "\\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "---\n",
    "1. Error Dependence on $\\sigma_0^{NM}$, fix $\\sigma_0^{AM}=0.5$ and vary $\\sigma_0^{NM}=0.1, 0.5, 1.0, 1.5, 2.0, 2.5$\n",
    "2. Error Dependence on $\\sigma_0^{AM}$, fix $\\sigma_0^{NM}=0.5$ and vary $\\sigma_0^{AM}=0.1, 0.5, 1.0, 1.5, 2.0, 2.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------\n",
    "# Robustness Analysis for NM \n",
    "#----------------------------\n",
    "\n",
    "def robust_analysis_NM():\n",
    "    sigma0_AM=0.5;  sigma0_NM=np.array([0.1, 0.5, 1.0, 1.5, 2.0, 2.5])\n",
    "    \n",
    "    # For kalman Filter, we use NM model with recursive formula and Riccati equation.\n",
    "    # But when applying KF procedure, use observation from AM that is y_n is from AM model.\n",
    "    \n",
    "    R0_NM=np.zeros((len(sigma0_NM),dimY,dimY))\n",
    "    \n",
    "    for i in range(len(sigma0_NM)):\n",
    "        \n",
    "        R0_NM[i]=sigma0_NM[i]*sigma0_NM[i]*R0\n",
    "        # first train a DF model with NM noise for use\n",
    "        datas, labels, x_hats, x_bars, x_raws, y_raws=sample_generator(Q0,R0_NM[i],sigma0_NM[i]) #!!!\n",
    "        model, data_mean, data_std, label_mean, label_std=deep_filtering(datas,labels,x_hats,x_bars,x_raws,y_raws)\n",
    "        \n",
    "        # second generating samples with AM model noise\n",
    "        x_raw_AM, y_raw_AM=ekf_mc(F0,h,u,v,x0,sigma0_AM,N)\n",
    "      \n",
    "        # Riccati equation with NM, observation with AM\n",
    "        x_hat, x_bar=extended_kf(f,g,h,F,G,H,Q0,R0_NM[i],x0,y_raw_AM,N)\n",
    "        \n",
    "        x_raw_AM=x_raw_AM.reshape(N+1,dimX)\n",
    "        y_raw_AM=y_raw_AM.reshape(N+1,dimY)\n",
    "        x_bar=x_bar.reshape(N+1,dimX)\n",
    "        data_new_AM=np.zeros((N-n0+2,n0,dimY))\n",
    "        \n",
    "        for k in range(N-n0+2):\n",
    "            data_new_AM[k]=y_raw_AM[k:k+n0]\n",
    "            \n",
    "        data_new_AM=data_new_AM.reshape(N-n0+2,n0*dimY)\n",
    "        data_new_AM=pd.DataFrame(data_new_AM)\n",
    "        # input normalization\n",
    "        data_new_AM=(data_new_AM-data_mean)/data_std # data_mean and data_std come from NM noise.\n",
    "        df_pred=model.predict(data_new_AM)\n",
    "        for k in range(N-n0+2):\n",
    "            # convect df results back to original scale.\n",
    "            df_pred[k,:]=df_pred[k,:]*label_std+label_mean\n",
    "            \n",
    "        from sklearn.metrics import mean_squared_error\n",
    "        # Deep Filtering Error\n",
    "        df_mse_err=mean_squared_error(x_raw_AM[n0-1:],df_pred)\n",
    "        kf_mse_err=mean_squared_error(x_raw_AM[n0-1:],x_bar[n0-1:])\n",
    "        \n",
    "        print(\"For fixed sigma0_AM and sigma0_NM %.2f, the mse errs of df and kf are: %.2f,%.2f\"%(sigma0_NM[i],df_mse_err, kf_mse_err))\n",
    "\n",
    "#----------------------------\n",
    "# Robustness Analysis for AM\n",
    "#----------------------------\n",
    "\n",
    "def robust_analysis_AM():\n",
    "    sigma0_AM=np.array([0.1, 0.5, 1.0, 1.5, 2.0, 2.5]); sigma0_NM=0.5  \n",
    "    \n",
    "    # For kalman Filter, we use NM model with recursive formula and Riccati equation.\n",
    "    # But when applying KF procedure, use observation from AM that is y_n is from AM model.\n",
    "    \n",
    "    R0_NM=sigma0_NM*sigma0_NM*R0\n",
    "    R0_AM=np.zeros((len(sigma0_AM),dimY,dimY))\n",
    "    \n",
    "    for i in range(len(sigma0_AM)):\n",
    "        \n",
    "        R0_AM[i]=sigma0_AM[i]*sigma0_AM[i]*R0\n",
    "        # first train a DF model with NM noise for use\n",
    "        datas, labels, x_hats, x_bars, x_raws, y_raws=sample_generator(Q0,R0_NM,sigma0_NM) #!!!\n",
    "        model, data_mean, data_std, label_mean, label_std=deep_filtering(datas,labels,x_hats,x_bars,x_raws,y_raws)\n",
    "        \n",
    "        # second generating samples with AM model noise\n",
    "        x_raw_AM, y_raw_AM=ekf_mc(F0,h,u,v,x0,sigma0_AM[i],N)\n",
    "        \n",
    "        # Riccati equation with NM, observation with AM\n",
    "        x_hat, x_bar=extended_kf(f,g,h,F,G,H,Q0,R0_NM,x0,y_raw_AM,N)\n",
    "        \n",
    "        x_raw_AM=x_raw_AM.reshape(N+1,dimX)\n",
    "        y_raw_AM=y_raw_AM.reshape(N+1,dimY)\n",
    "        x_bar=x_bar.reshape(N+1,dimX)\n",
    "        data_new_AM=np.zeros((N-n0+2,n0,dimY))\n",
    "        \n",
    "        for k in range(N-n0+2):\n",
    "            data_new_AM[k]=y_raw_AM[k:k+n0]\n",
    "            \n",
    "        data_new_AM=data_new_AM.reshape(N-n0+2,n0*dimY)\n",
    "        data_new_AM=pd.DataFrame(data_new_AM)\n",
    "        # input normalization\n",
    "        data_new_AM=(data_new_AM-data_mean)/data_std # data_mean and data_std come from NM noise.\n",
    "        df_pred=model.predict(data_new_AM)\n",
    "        for k in range(N-n0+2):\n",
    "            # convect df results back to original scale.\n",
    "            df_pred[k,:]=df_pred[k,:]*label_std+label_mean\n",
    "            \n",
    "        from sklearn.metrics import mean_squared_error\n",
    "        # Deep Filtering Error\n",
    "        df_mse_err=mean_squared_error(x_raw_AM[n0-1:],df_pred)\n",
    "        kf_mse_err=mean_squared_error(x_raw_AM[n0-1:],x_bar[n0-1:])\n",
    "        print(\"For fixed sigma0_NM and sigma0_AM %.2f, the mse errs of df and kf are: %.2f, %.2f\"%(sigma0_AM[i],df_mse_err, kf_mse_err))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47600/47600 [==============================] - 19s 391us/step - loss: 0.3740 - mean_squared_error: 0.3740\n",
      "Epoch 2/10\n",
      "47600/47600 [==============================] - 19s 392us/step - loss: 0.1125 - mean_squared_error: 0.1125\n",
      "Epoch 3/10\n",
      "47600/47600 [==============================] - 19s 400us/step - loss: 0.1034 - mean_squared_error: 0.1034\n",
      "Epoch 4/10\n",
      "47600/47600 [==============================] - 19s 390us/step - loss: 0.0975 - mean_squared_error: 0.0975\n",
      "Epoch 5/10\n",
      "47600/47600 [==============================] - 18s 389us/step - loss: 0.0835 - mean_squared_error: 0.0835\n",
      "Epoch 6/10\n",
      "47600/47600 [==============================] - 19s 389us/step - loss: 0.0641 - mean_squared_error: 0.0641\n",
      "Epoch 7/10\n",
      "47600/47600 [==============================] - 19s 389us/step - loss: 0.0535 - mean_squared_error: 0.0535\n",
      "Epoch 8/10\n",
      "47600/47600 [==============================] - 19s 389us/step - loss: 0.0492 - mean_squared_error: 0.0492\n",
      "Epoch 9/10\n",
      "47600/47600 [==============================] - 19s 389us/step - loss: 0.0475 - mean_squared_error: 0.0475\n",
      "Epoch 10/10\n",
      "47600/47600 [==============================] - 19s 389us/step - loss: 0.0465 - mean_squared_error: 0.0465\n",
      "5950/5950 [==============================] - 2s 345us/step - loss: 0.0462 - mean_squared_error: 0.0462\n",
      "For fixed sigma0_AM and sigma0_NM 0.10, the mse errs of df and kf are: 94161.81,34293026.18\n",
      "Epoch 1/10\n",
      "47600/47600 [==============================] - 19s 393us/step - loss: 0.3746 - mean_squared_error: 0.3746\n",
      "Epoch 2/10\n",
      "47600/47600 [==============================] - 19s 391us/step - loss: 0.1314 - mean_squared_error: 0.1314\n",
      "Epoch 3/10\n",
      "47600/47600 [==============================] - 19s 392us/step - loss: 0.0950 - mean_squared_error: 0.0950\n",
      "Epoch 4/10\n",
      "47600/47600 [==============================] - 19s 393us/step - loss: 0.0764 - mean_squared_error: 0.0764\n",
      "Epoch 5/10\n",
      "47600/47600 [==============================] - 19s 392us/step - loss: 0.0659 - mean_squared_error: 0.0659\n",
      "Epoch 6/10\n",
      "47600/47600 [==============================] - 19s 392us/step - loss: 0.0614 - mean_squared_error: 0.0614\n",
      "Epoch 7/10\n",
      "47600/47600 [==============================] - 19s 393us/step - loss: 0.0585 - mean_squared_error: 0.0585\n",
      "Epoch 8/10\n",
      "47600/47600 [==============================] - 19s 395us/step - loss: 0.0567 - mean_squared_error: 0.0567\n",
      "Epoch 9/10\n",
      "47600/47600 [==============================] - 19s 396us/step - loss: 0.0557 - mean_squared_error: 0.0557\n",
      "Epoch 10/10\n",
      "47600/47600 [==============================] - 19s 394us/step - loss: 0.0551 - mean_squared_error: 0.0551\n",
      "5950/5950 [==============================] - 2s 337us/step - loss: 0.0548 - mean_squared_error: 0.0548\n",
      "For fixed sigma0_AM and sigma0_NM 0.50, the mse errs of df and kf are: 34701.93,340374.34\n",
      "Epoch 1/10\n",
      "    1/47600 [..............................] - ETA: 0s - loss: 0.9763 - mean_squared_error: 0.9763WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "47600/47600 [==============================] - 19s 396us/step - loss: 0.4203 - mean_squared_error: 0.4203\n",
      "Epoch 2/10\n",
      "47600/47600 [==============================] - 19s 396us/step - loss: 0.2001 - mean_squared_error: 0.2001\n",
      "Epoch 3/10\n",
      "47600/47600 [==============================] - 19s 398us/step - loss: 0.1517 - mean_squared_error: 0.1517\n",
      "Epoch 4/10\n",
      "47600/47600 [==============================] - 19s 396us/step - loss: 0.1229 - mean_squared_error: 0.1229\n",
      "Epoch 5/10\n",
      "47600/47600 [==============================] - 19s 395us/step - loss: 0.1162 - mean_squared_error: 0.1162\n",
      "Epoch 6/10\n",
      "47600/47600 [==============================] - 19s 397us/step - loss: 0.1125 - mean_squared_error: 0.1125\n",
      "Epoch 7/10\n",
      "47600/47600 [==============================] - 19s 395us/step - loss: 0.1099 - mean_squared_error: 0.1099\n",
      "Epoch 8/10\n",
      "47600/47600 [==============================] - 19s 398us/step - loss: 0.1077 - mean_squared_error: 0.1077\n",
      "Epoch 9/10\n",
      "47600/47600 [==============================] - 19s 397us/step - loss: 0.1056 - mean_squared_error: 0.1056\n",
      "Epoch 10/10\n",
      "47600/47600 [==============================] - 19s 401us/step - loss: 0.1037 - mean_squared_error: 0.1037\n",
      "5950/5950 [==============================] - 2s 346us/step - loss: 0.1027 - mean_squared_error: 0.1027\n",
      "For fixed sigma0_AM and sigma0_NM 1.00, the mse errs of df and kf are: 100418.70,1719217.41\n",
      "Epoch 1/10\n",
      "47600/47600 [==============================] - 19s 408us/step - loss: 0.3384 - mean_squared_error: 0.3384\n",
      "Epoch 2/10\n",
      "47600/47600 [==============================] - 19s 407us/step - loss: 0.1595 - mean_squared_error: 0.1595\n",
      "Epoch 3/10\n",
      "47600/47600 [==============================] - 19s 407us/step - loss: 0.1354 - mean_squared_error: 0.1354\n",
      "Epoch 4/10\n",
      "47600/47600 [==============================] - 20s 413us/step - loss: 0.1159 - mean_squared_error: 0.1159\n",
      "Epoch 5/10\n",
      "47600/47600 [==============================] - 19s 407us/step - loss: 0.0991 - mean_squared_error: 0.0991\n",
      "Epoch 6/10\n",
      "47600/47600 [==============================] - 20s 415us/step - loss: 0.0859 - mean_squared_error: 0.0859\n",
      "Epoch 7/10\n",
      "47600/47600 [==============================] - 19s 409us/step - loss: 0.0773 - mean_squared_error: 0.0773\n",
      "Epoch 8/10\n",
      "47600/47600 [==============================] - 19s 407us/step - loss: 0.0731 - mean_squared_error: 0.0731\n",
      "Epoch 9/10\n",
      "47600/47600 [==============================] - 19s 407us/step - loss: 0.0707 - mean_squared_error: 0.0707\n",
      "Epoch 10/10\n",
      "47600/47600 [==============================] - 19s 408us/step - loss: 0.0691 - mean_squared_error: 0.0691\n",
      "5950/5950 [==============================] - 2s 343us/step - loss: 0.0681 - mean_squared_error: 0.0681\n",
      "For fixed sigma0_AM and sigma0_NM 1.50, the mse errs of df and kf are: 85263.00,862602.65\n",
      "Epoch 1/10\n",
      "47600/47600 [==============================] - 19s 396us/step - loss: 0.3455 - mean_squared_error: 0.3455\n",
      "Epoch 2/10\n",
      "47600/47600 [==============================] - 19s 396us/step - loss: 0.1548 - mean_squared_error: 0.1548\n",
      "Epoch 3/10\n",
      "47600/47600 [==============================] - 19s 396us/step - loss: 0.1408 - mean_squared_error: 0.1408\n",
      "Epoch 4/10\n",
      "47600/47600 [==============================] - 19s 395us/step - loss: 0.1372 - mean_squared_error: 0.1372\n",
      "Epoch 5/10\n",
      "47600/47600 [==============================] - 19s 395us/step - loss: 0.1348 - mean_squared_error: 0.1348\n",
      "Epoch 6/10\n",
      "47600/47600 [==============================] - 19s 397us/step - loss: 0.1331 - mean_squared_error: 0.1331\n",
      "Epoch 7/10\n",
      "47600/47600 [==============================] - 19s 395us/step - loss: 0.1316 - mean_squared_error: 0.1316\n",
      "Epoch 8/10\n",
      "47600/47600 [==============================] - 19s 398us/step - loss: 0.1302 - mean_squared_error: 0.1302\n",
      "Epoch 9/10\n",
      "47600/47600 [==============================] - 19s 396us/step - loss: 0.1288 - mean_squared_error: 0.1288\n",
      "Epoch 10/10\n",
      "47600/47600 [==============================] - 19s 396us/step - loss: 0.1274 - mean_squared_error: 0.1274\n",
      "5950/5950 [==============================] - 2s 351us/step - loss: 0.1261 - mean_squared_error: 0.1261\n",
      "For fixed sigma0_AM and sigma0_NM 2.00, the mse errs of df and kf are: 152328.52,1203466.00\n",
      "Epoch 1/10\n",
      "47600/47600 [==============================] - 19s 401us/step - loss: 0.6717 - mean_squared_error: 0.6717\n",
      "Epoch 2/10\n",
      "47600/47600 [==============================] - 19s 399us/step - loss: 0.3159 - mean_squared_error: 0.3159\n",
      "Epoch 3/10\n",
      "47600/47600 [==============================] - 19s 399us/step - loss: 0.1931 - mean_squared_error: 0.1931\n",
      "Epoch 4/10\n",
      "47600/47600 [==============================] - 19s 397us/step - loss: 0.1803 - mean_squared_error: 0.1803\n",
      "Epoch 5/10\n",
      "47600/47600 [==============================] - 19s 404us/step - loss: 0.1761 - mean_squared_error: 0.1761\n",
      "Epoch 6/10\n",
      "47600/47600 [==============================] - 19s 398us/step - loss: 0.1713 - mean_squared_error: 0.1713\n",
      "Epoch 7/10\n",
      "47600/47600 [==============================] - 19s 398us/step - loss: 0.1679 - mean_squared_error: 0.1679\n",
      "Epoch 8/10\n",
      "47600/47600 [==============================] - 19s 396us/step - loss: 0.1654 - mean_squared_error: 0.1654\n",
      "Epoch 9/10\n",
      "47600/47600 [==============================] - 19s 397us/step - loss: 0.1630 - mean_squared_error: 0.1630\n",
      "Epoch 10/10\n",
      "47600/47600 [==============================] - 19s 395us/step - loss: 0.1606 - mean_squared_error: 0.1606\n",
      "5950/5950 [==============================] - 2s 345us/step - loss: 0.1589 - mean_squared_error: 0.1589\n",
      "For fixed sigma0_AM and sigma0_NM 2.50, the mse errs of df and kf are: 160848.34,907878.63\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-f8733c7a325c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrobust_analysis_NM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrobust_analysis_AM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-34-7f8013d32971>\u001b[0m in \u001b[0;36mrobust_analysis_AM\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mR0_NM\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msigma0_NM\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msigma0_NM\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mR0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0mR0_AM\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigma0_NM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdimY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdimY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigma0_AM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "robust_analysis_NM()\n",
    "robust_analysis_AM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
